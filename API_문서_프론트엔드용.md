# ğŸ¯ CampusON ë°±ì—”ë“œ API ì™„ì „ ê°œë°œ ê°€ì´ë“œ

## ğŸ“‹ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ê°œìš”

### ğŸ—ï¸ ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡°
```
Frontend (React) â†â†’ FastAPI Backend â†â†’ PostgreSQL Database
                          â†“
                    OpenAI GPT-4o-mini
                          â†“
                    AI ë¶„ì„ & ì¶”ì²œ ì‹œìŠ¤í…œ
```

### ğŸ”„ ë°ì´í„° í”Œë¡œìš°
1. **ì‚¬ìš©ì ì¸ì¦** â†’ JWT í† í° ë°œê¸‰ â†’ ì„¸ì…˜ ê´€ë¦¬
2. **ì§„ë‹¨ ì‹œìŠ¤í…œ** â†’ AI ë¶„ì„ â†’ í•™ìŠµ ìˆ˜ì¤€ ê³„ì‚° â†’ ê°œì¸í™” ì¶”ì²œ
3. **ëŒ€ì‹œë³´ë“œ** â†’ ì‹¤ì‹œê°„ ë°ì´í„° ì§‘ê³„ â†’ ì‹œê°í™” ë°ì´í„° ì œê³µ
4. **AI ì„œë¹„ìŠ¤** â†’ OpenAI API í˜¸ì¶œ â†’ ë¶„ì„ ê²°ê³¼ ìºì‹±

**ë² ì´ìŠ¤ URL**: `http://localhost:8000/api`

---

## ğŸ” ì¸ì¦ ì‹œìŠ¤í…œ ìƒì„¸

### ğŸ« JWT í† í° êµ¬ì¡°
```json
{
  "header": {
    "alg": "HS256",
    "typ": "JWT"
  },
  "payload": {
    "sub": "user_id",
    "exp": 1640995200,
    "iat": 1640908800,
    "user_type": "student|professor|admin"
  }
}
```

### ğŸ”‘ ì¸ì¦ í”Œë¡œìš°
```mermaid
sequenceDiagram
    Frontend->>Backend: POST /auth/login
    Backend->>Database: ì‚¬ìš©ì ê²€ì¦
    Backend->>Frontend: JWT í† í° ë°˜í™˜
    Frontend->>Backend: API ìš”ì²­ (Bearer Token)
    Backend->>Backend: í† í° ê²€ì¦
    Backend->>Frontend: ì¸ì¦ëœ ì‘ë‹µ
```

### ğŸ“ ì¸ì¦ í—¤ë” ì„¤ì •
```javascript
// JavaScript/React ì˜ˆì‹œ
const api = axios.create({
  baseURL: 'http://localhost:8000/api',
  headers: {
    'Authorization': `Bearer ${localStorage.getItem('token')}`,
    'Content-Type': 'application/json'
  }
});
```

---

## ğŸ“Š 1. í•™ìƒ ëŒ€ì‹œë³´ë“œ API ì‹œìŠ¤í…œ (3ìˆœìœ„)

### ğŸ›ï¸ ì•„í‚¤í…ì²˜ êµ¬ì¡°
```
Controller (dashboard.py) â†’ Service (dashboard_service.py) â†’ Database Models
                         â†“
                   Schema Validation (dashboard.py)
```

### ğŸ“ˆ 1.1 ëŒ€ì‹œë³´ë“œ ê°œìš” API
```http
GET /dashboard/overview
Authorization: Bearer {token}
```

**êµ¬ë™ ì›ë¦¬:**
1. JWT í† í°ì—ì„œ `user_id` ì¶”ì¶œ
2. `diagnosis_results` í…Œì´ë¸”ì—ì„œ ìµœì‹  í•™ìŠµ ìˆ˜ì¤€ ì¡°íšŒ
3. `user_histories` í…Œì´ë¸”ì—ì„œ í™œë™ ì´ë ¥ ì§‘ê³„
4. ì‹¤ì‹œê°„ í†µê³„ ê³„ì‚° ë° ë°˜í™˜

**ì‘ë‹µ ìŠ¤í‚¤ë§ˆ:**
```python
class StudentDashboardResponse(BaseModel):
    student_name: str
    current_level: float        # 0.0 ~ 1.0 (ì‚°ìˆ ì‹ ê¸°ë°˜)
    level_change: float         # ìµœê·¼ ë³€í™”ëŸ‰
    total_problems_solved: int  # ëˆ„ì  ë¬¸ì œ í•´ê²° ìˆ˜
    current_streak: int         # ì—°ì† í•™ìŠµ ì¼ìˆ˜
    upcoming_deadlines: List[DeadlineItem]
    recent_activities: List[ActivityItem]
    quick_recommendations: List[RecommendationItem]
```

**í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™:**
```javascript
// React Hook ì˜ˆì‹œ
const useDashboard = () => {
  const [dashboard, setDashboard] = useState(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    const fetchDashboard = async () => {
      try {
        const response = await api.get('/dashboard/overview');
        setDashboard(response.data);
      } catch (error) {
        console.error('ëŒ€ì‹œë³´ë“œ ë¡œë”© ì‹¤íŒ¨:', error);
      } finally {
        setLoading(false);
      }
    };

    fetchDashboard();
    // 5ë¶„ë§ˆë‹¤ ìë™ ê°±ì‹ 
    const interval = setInterval(fetchDashboard, 300000);
    return () => clearInterval(interval);
  }, []);

  return { dashboard, loading };
};
```

### ğŸ“š 1.2 í•™ìŠµ ì§„ì²™ë„ ìƒì„¸ API
```http
GET /dashboard/progress?period_days=30&subject=database
```

**ë§¤ê°œë³€ìˆ˜:**
- `period_days`: ì¡°íšŒ ê¸°ê°„ (ê¸°ë³¸ê°’: 30ì¼)
- `subject`: íŠ¹ì • ê³¼ëª© í•„í„° (ì„ íƒì )

**êµ¬ë™ ì›ë¦¬:**
1. `period_days` ê¸°ê°„ ë‚´ ëª¨ë“  ì§„ë‹¨ ê²°ê³¼ ì¡°íšŒ
2. ê³¼ëª©ë³„ ì„±ê³¼ ë³€í™” ì¶”ì´ ê³„ì‚°
3. ë‚œì´ë„ë³„ ì •ë‹µë¥  ë¶„ì„
4. í•™ìŠµ íŒ¨í„´ ì‹œê°„ëŒ€ë³„ ë¶„ì„

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
  "period": {
    "start_date": "2024-05-01",
    "end_date": "2024-05-30",
    "total_days": 30
  },
  "overall_progress": {
    "start_level": 0.65,
    "end_level": 0.72,
    "improvement_rate": 0.107,
    "consistency_score": 0.85
  },
  "subject_breakdown": {
    "database": {
      "level": 0.75,
      "problems_solved": 45,
      "improvement": 0.12
    },
    "algorithm": {
      "level": 0.68,
      "problems_solved": 32,
      "improvement": 0.08
    }
  },
  "daily_progress": [
    {
      "date": "2024-05-01",
      "level": 0.65,
      "problems_solved": 3,
      "time_spent_minutes": 45
    }
    // ... 30ì¼ê°„ ë°ì´í„°
  ],
  "learning_patterns": {
    "peak_hours": ["14:00-16:00", "20:00-22:00"],
    "preferred_difficulty": 3,
    "average_session_duration": 35
  }
}
```

### ğŸ“‹ 1.3 ê°œì¸ ë§ì¶¤ í•™ìŠµ ê³„íš API
```http
GET /dashboard/study-plan?weeks=4
```

**AI ê¸°ë°˜ ê³„íš ìƒì„± ê³¼ì •:**
1. ì‚¬ìš©ìì˜ í˜„ì¬ í•™ìŠµ ìˆ˜ì¤€ ë¶„ì„
2. ì•½ì  ì˜ì—­ ì‹ë³„ (ì •ë‹µë¥  ë‚®ì€ ë‚œì´ë„/ê³¼ëª©)
3. ëª©í‘œ ì„¤ì • (4ì£¼ í›„ ë„ë‹¬ ê°€ëŠ¥í•œ ìˆ˜ì¤€)
4. ì¼ë³„ í•™ìŠµëŸ‰ ë° ìš°ì„ ìˆœìœ„ ê³„ì‚°

**ê³„íš ìƒì„± ì•Œê³ ë¦¬ì¦˜:**
```python
def generate_study_plan(user_id: int, weeks: int):
    # 1. í˜„ì¬ ìˆ˜ì¤€ ë¶„ì„
    current_level = get_current_level(user_id)
    weak_areas = identify_weak_areas(user_id)
    
    # 2. ëª©í‘œ ìˆ˜ì¤€ ê³„ì‚° (í˜„ì‹¤ì  í–¥ìƒë¥  ì ìš©)
    target_level = min(current_level + (0.1 * weeks), 1.0)
    
    # 3. ì¼ë³„ ê³„íš ìƒì„±
    daily_plans = []
    for week in range(weeks):
        for day in range(7):
            plan = calculate_daily_plan(
                current_level, target_level, weak_areas, week, day
            )
            daily_plans.append(plan)
    
    return daily_plans
```

### ğŸ¯ 1.4 ë§ì¶¤í˜• ì¶”ì²œ ì‹œìŠ¤í…œ
```http
GET /dashboard/recommendations?limit=10&type=all
```

**ì¶”ì²œ íƒ€ì…:**
- `practice`: ì—°ìŠµ ë¬¸ì œ ì¶”ì²œ
- `review`: ë³µìŠµ í•„ìš” í•­ëª©
- `challenge`: ë„ì „ ê³¼ì œ
- `weak_area`: ì•½ì  ë³´ê°•

**ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜:**
```python
class RecommendationEngine:
    def generate_recommendations(self, user_id: int, limit: int):
        # 1. ì‚¬ìš©ì í”„ë¡œí•„ ë¶„ì„
        profile = self.analyze_user_profile(user_id)
        
        # 2. í˜‘ì—… í•„í„°ë§ (ìœ ì‚¬ ì‚¬ìš©ì ê¸°ë°˜)
        similar_users = self.find_similar_users(profile)
        collaborative_recs = self.get_collaborative_recommendations(similar_users)
        
        # 3. ì»¨í…ì¸  ê¸°ë°˜ í•„í„°ë§ (ê°œì¸ ì„±ê³¼ ê¸°ë°˜)
        content_recs = self.get_content_based_recommendations(profile)
        
        # 4. í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§
        final_recs = self.hybrid_scoring(collaborative_recs, content_recs)
        
        return final_recs[:limit]
```

---

## ğŸ¤– 2. AI ì„œë¹„ìŠ¤ ì‹œìŠ¤í…œ (4ìˆœìœ„)

### ğŸ§  AI ì•„í‚¤í…ì²˜
```
FastAPI Endpoint â†’ AIService â†’ OpenAI GPT-4o-mini â†’ Response Processing
                      â†“
               Cache Layer (Redis) â†’ Database Storage
```

### ğŸ” 2.1 í•™ìŠµ íŒ¨í„´ AI ë¶„ì„
```http
GET /ai/analyze/learning-pattern
```

**AI ë¶„ì„ ê³¼ì •:**
1. **ë°ì´í„° ìˆ˜ì§‘**: ìµœê·¼ 30ì¼ê°„ í•™ìŠµ ì´ë ¥ ì¡°íšŒ
2. **íŒ¨í„´ ì¶”ì¶œ**: ì‹œê°„ëŒ€ë³„, ë‚œì´ë„ë³„, ê³¼ëª©ë³„ ì„±ê³¼ ë¶„ì„
3. **AI í”„ë¡¬í”„íŠ¸ ìƒì„±**: êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ìì—°ì–´ë¡œ ë³€í™˜
4. **GPT ë¶„ì„**: í•™ìŠµ íŒ¨í„´ í•´ì„ ë° ì¸ì‚¬ì´íŠ¸ ìƒì„±
5. **ê²°ê³¼ í›„ì²˜ë¦¬**: JSON êµ¬ì¡°í™” ë° ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°

**AI í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ:**
```python
def create_learning_pattern_prompt(user_data):
    return f"""
    ë‹¤ìŒ í•™ìŠµ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í•™ìŠµ íŒ¨í„´ì„ íŒŒì•…í•´ì£¼ì„¸ìš”:
    
    í•™ìŠµ ì´ë ¥:
    - ì´ í•™ìŠµ ì‹œê°„: {user_data['total_hours']}ì‹œê°„
    - ë¬¸ì œ í•´ê²° ìˆ˜: {user_data['problems_solved']}ê°œ
    - í‰ê·  ì •ë‹µë¥ : {user_data['accuracy']:.1%}
    
    ì‹œê°„ëŒ€ë³„ ì„±ê³¼:
    {format_hourly_performance(user_data['hourly_stats'])}
    
    ë‚œì´ë„ë³„ ì„±ê³¼:
    {format_difficulty_performance(user_data['difficulty_stats'])}
    
    ë¶„ì„ ìš”ì²­ì‚¬í•­:
    1. ì£¼ìš” í•™ìŠµ íŒ¨í„´ 3ê°€ì§€
    2. ê°•ì ê³¼ ì•½ì  ê°ê° 3ê°€ì§€
    3. ê°œì„  ë°©ì•ˆ 5ê°€ì§€
    4. ì „ì²´ ë¶„ì„ì˜ ì‹ ë¢°ë„ (0-1)
    
    JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
    """
```

**ì‘ë‹µ ì²˜ë¦¬:**
```python
class AIService:
    async def analyze_learning_pattern(self, user_id: int):
        # 1. ì‚¬ìš©ì ë°ì´í„° ìˆ˜ì§‘
        user_data = await self.collect_user_data(user_id)
        
        # 2. AI ë¶„ì„ ìš”ì²­
        prompt = self.create_learning_pattern_prompt(user_data)
        ai_response = await self.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        # 3. ì‘ë‹µ íŒŒì‹±
        analysis = json.loads(ai_response.choices[0].message.content)
        
        # 4. ê²°ê³¼ ê²€ì¦ ë° í›„ì²˜ë¦¬
        validated_result = self.validate_analysis_result(analysis)
        
        # 5. ìºì‹œ ì €ì¥
        await self.cache_analysis_result(user_id, validated_result)
        
        return validated_result
```

### ğŸ—ºï¸ 2.2 ê°œì¸ ë§ì¶¤ í•™ìŠµ ê²½ë¡œ ìƒì„±
```http
GET /ai/generate/study-path?target_weeks=8&focus_area=algorithm
```

**í•™ìŠµ ê²½ë¡œ ìƒì„± ì•Œê³ ë¦¬ì¦˜:**
```python
def generate_study_path(user_id, target_weeks, focus_area):
    # 1. í˜„ì¬ ìˆ˜ì¤€ í‰ê°€
    current_assessment = assess_current_level(user_id, focus_area)
    
    # 2. ëª©í‘œ ì„¤ì •
    target_level = calculate_realistic_target(current_assessment, target_weeks)
    
    # 3. ë§ˆì¼ìŠ¤í†¤ ê³„íš
    milestones = create_weekly_milestones(current_assessment, target_level, target_weeks)
    
    # 4. ì„¸ë¶€ ê³„íš ìƒì„±
    detailed_path = []
    for week, milestone in enumerate(milestones):
        week_plan = {
            "week": week + 1,
            "goal": milestone,
            "daily_tasks": generate_daily_tasks(milestone),
            "practice_problems": select_practice_problems(milestone),
            "assessment": create_weekly_assessment(milestone)
        }
        detailed_path.append(week_plan)
    
    return detailed_path
```

### ğŸ”® 2.3 ì„±ê³¼ ì˜ˆì¸¡ ëª¨ë¸
```http
GET /ai/predict/performance?subject=database&prediction_days=30
```

**ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¡°:**
```python
class PerformancePredictionModel:
    def __init__(self):
        self.features = [
            'current_level', 'learning_consistency', 'time_spent_daily',
            'difficulty_progression', 'weak_area_improvement_rate'
        ]
    
    def predict(self, user_id: int, subject: str, days: int):
        # 1. íŠ¹ì„± ì¶”ì¶œ
        features = self.extract_features(user_id, subject)
        
        # 2. íŠ¸ë Œë“œ ë¶„ì„
        trend = self.analyze_trend(features, days)
        
        # 3. í™•ë¥ ì  ì˜ˆì¸¡
        predictions = []
        for day in range(1, days + 1):
            predicted_level = self.predict_daily_level(features, trend, day)
            confidence = self.calculate_confidence(features, day)
            
            predictions.append({
                "day": day,
                "predicted_level": predicted_level,
                "confidence": confidence,
                "factors": self.get_influencing_factors(features, day)
            })
        
        return predictions
```

---

## ğŸ‘¨â€ğŸ« 3. êµìˆ˜ ëŒ€ì‹œë³´ë“œ ì‹œìŠ¤í…œ (6ìˆœìœ„)

### ğŸ“Š 3.1 êµìˆ˜ ëŒ€ì‹œë³´ë“œ ì „ì²´ ê°œìš”
```http
GET /professor/dashboard
```

**ë°ì´í„° ì§‘ê³„ ê³¼ì •:**
1. **ìˆ˜ì—… ë°ì´í„° ì§‘ê³„**: ë‹´ë‹¹ ìˆ˜ì—…ë³„ í•™ìƒ ìˆ˜, ì§„ë„ìœ¨ ê³„ì‚°
2. **ì„±ê³¼ ë¶„ì„**: í‰ê·  ì ìˆ˜, ê°œì„ ë¥ , ì™„ë£Œìœ¨ í†µê³„
3. **ìµœê·¼ í™œë™**: ì œì¶œë¬¼, ì§ˆë¬¸, ì„±ê³¼ ë³€í™” ëª¨ë‹ˆí„°ë§
4. **ì•Œë¦¼ ìƒì„±**: ì£¼ì˜ í•„ìš” í•™ìƒ, ëŒ€ê¸° ì¤‘ì¸ ì‘ì—… ì‹ë³„

**ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬:**
```python
class ProfessorDashboardService:
    async def get_dashboard_overview(self, professor_id: int):
        # ë™ì‹œ ë°ì´í„° ì¡°íšŒë¡œ ì„±ëŠ¥ ìµœì í™”
        tasks = [
            self.get_class_summary(professor_id),
            self.get_student_performance(professor_id),
            self.get_recent_activities(professor_id),
            self.get_pending_tasks(professor_id)
        ]
        
        class_summary, performance, activities, tasks = await asyncio.gather(*tasks)
        
        return ProfessorDashboardResponse(
            professor_name=await self.get_professor_name(professor_id),
            class_summary=class_summary,
            performance_overview=performance,
            recent_activities=activities,
            pending_tasks=tasks,
            last_updated=datetime.now(timezone.utc)
        )
```

### ğŸ‘¥ 3.2 í•™ìƒ ì§„ë„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
```http
GET /professor/students/progress?class_id=1&sort=progress_asc&filter=struggling
```

**ì§„ë„ ê³„ì‚° ì•Œê³ ë¦¬ì¦˜:**
```python
def calculate_student_progress(student_id: int, class_id: int):
    # 1. ì˜ˆìƒ ì§„ë„ ê³„ì‚°
    total_weeks = get_semester_weeks()
    current_week = get_current_week()
    expected_progress = current_week / total_weeks
    
    # 2. ì‹¤ì œ ì§„ë„ ê³„ì‚°
    completed_assignments = count_completed_assignments(student_id, class_id)
    total_assignments = count_total_assignments(class_id)
    actual_progress = completed_assignments / total_assignments
    
    # 3. ì§„ë„ ìƒíƒœ ë¶„ë¥˜
    progress_ratio = actual_progress / expected_progress
    
    if progress_ratio >= 1.1:
        status = "ahead"
    elif progress_ratio >= 0.9:
        status = "on_track"
    elif progress_ratio >= 0.7:
        status = "behind"
    else:
        status = "struggling"
    
    return {
        "student_id": student_id,
        "expected_progress": expected_progress,
        "actual_progress": actual_progress,
        "status": status,
        "last_activity": get_last_activity(student_id, class_id)
    }
```

### ğŸ“ 3.3 AI ê¸°ë°˜ ê³¼ì œ ìƒì„± ì‹œìŠ¤í…œ
```http
POST /professor/assignment
Content-Type: application/json

{
  "class_id": 1,
  "title": "ë°ì´í„°ë² ì´ìŠ¤ ì •ê·œí™” ê³¼ì œ",
  "learning_objectives": ["3NF ì´í•´", "ERD ì‘ì„±", "SQL ì¿¼ë¦¬ ìµœì í™”"],
  "difficulty_level": 3,
  "estimated_hours": 4,
  "due_date": "2024-06-15T23:59:59",
  "auto_generate_problems": true
}
```

**ê³¼ì œ ìƒì„± ê³¼ì •:**
```python
class AssignmentGenerator:
    async def create_assignment(self, assignment_data: AssignmentCreate):
        # 1. í•™ìŠµ ëª©í‘œ ë¶„ì„
        objectives = self.analyze_learning_objectives(assignment_data.learning_objectives)
        
        # 2. ì ì ˆí•œ ë‚œì´ë„ ë¬¸ì œ ì„ íƒ
        problems = await self.select_problems(
            objectives=objectives,
            difficulty=assignment_data.difficulty_level,
            estimated_hours=assignment_data.estimated_hours
        )
        
        # 3. AI ê¸°ë°˜ ì¶”ê°€ ë¬¸ì œ ìƒì„± (ì˜µì…˜)
        if assignment_data.auto_generate_problems:
            ai_problems = await self.generate_ai_problems(objectives, problems)
            problems.extend(ai_problems)
        
        # 4. ê³¼ì œ êµ¬ì¡°í™”
        assignment = Assignment(
            title=assignment_data.title,
            problems=problems,
            rubric=self.generate_rubric(objectives),
            due_date=assignment_data.due_date
        )
        
        # 5. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        return await self.save_assignment(assignment)
```

---

## ğŸ”’ 4. ê³ ê¸‰ ë³´ì•ˆ ì‹œìŠ¤í…œ (7ìˆœìœ„)

### ğŸ›¡ï¸ 4.1 ë‹¤ì¸µ ë³´ì•ˆ ì•„í‚¤í…ì²˜
```
Frontend â†’ Rate Limiter â†’ Authentication â†’ Authorization â†’ API Handler
              â†“              â†“              â†“
         Redis Cache â†’ JWT Validation â†’ Role Check â†’ Audit Log
```

### ğŸ” 4.2 ë¡œê·¸ì¸ ë³´ì•ˆ ë¶„ì„
```http
GET /security/analyze/login
```

**ìœ„í—˜ë„ ê³„ì‚° ì•Œê³ ë¦¬ì¦˜:**
```python
class SecurityAnalyzer:
    def calculate_risk_score(self, login_data: LoginAttempt):
        risk_factors = []
        
        # 1. IP ì£¼ì†Œ ë¶„ì„
        ip_risk = self.analyze_ip_address(login_data.ip_address)
        risk_factors.append(('ip_address', ip_risk, 0.3))
        
        # 2. ì§€ë¦¬ì  ìœ„ì¹˜ ë¶„ì„
        location_risk = self.analyze_location(login_data.location)
        risk_factors.append(('location', location_risk, 0.25))
        
        # 3. ë””ë°”ì´ìŠ¤ ì§€ë¬¸ ë¶„ì„
        device_risk = self.analyze_device_fingerprint(login_data.device_info)
        risk_factors.append(('device', device_risk, 0.2))
        
        # 4. ì‹œê°„ íŒ¨í„´ ë¶„ì„
        time_risk = self.analyze_time_pattern(login_data.timestamp)
        risk_factors.append(('time_pattern', time_risk, 0.15))
        
        # 5. í–‰ë™ íŒ¨í„´ ë¶„ì„
        behavior_risk = self.analyze_behavior_pattern(login_data.user_id)
        risk_factors.append(('behavior', behavior_risk, 0.1))
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        total_score = sum(score * weight for _, score, weight in risk_factors)
        
        return {
            'total_risk_score': total_score,
            'risk_level': self.categorize_risk(total_score),
            'contributing_factors': risk_factors,
            'recommendations': self.generate_recommendations(risk_factors)
        }
```

### ğŸ“± 4.3 2ë‹¨ê³„ ì¸ì¦ ì‹œìŠ¤í…œ
```http
POST /security/2fa/setup?method=totp
```

**TOTP êµ¬í˜„:**
```python
import pyotp
import qrcode

class TwoFactorAuth:
    def setup_totp(self, user_id: int):
        # 1. ì‚¬ìš©ìë³„ ë¹„ë°€ í‚¤ ìƒì„±
        secret_key = pyotp.random_base32()
        
        # 2. TOTP ê°ì²´ ìƒì„±
        totp = pyotp.TOTP(secret_key)
        
        # 3. QR ì½”ë“œ ìƒì„±ì„ ìœ„í•œ URL
        provisioning_uri = totp.provisioning_uri(
            name=f"user_{user_id}",
            issuer_name="CampusON"
        )
        
        # 4. QR ì½”ë“œ ì´ë¯¸ì§€ ìƒì„±
        qr = qrcode.QRCode(version=1, box_size=10, border=5)
        qr.add_data(provisioning_uri)
        qr.make(fit=True)
        qr_image = qr.make_image(fill_color="black", back_color="white")
        
        # 5. ì‚¬ìš©ì ì •ë³´ì— ì €ì¥
        await self.save_2fa_secret(user_id, secret_key)
        
        return {
            'secret_key': secret_key,
            'qr_code_url': self.save_qr_image(qr_image),
            'backup_codes': self.generate_backup_codes(user_id)
        }
    
    def verify_totp(self, user_id: int, token: str):
        secret_key = await self.get_2fa_secret(user_id)
        totp = pyotp.TOTP(secret_key)
        return totp.verify(token, valid_window=1)  # 30ì´ˆ í—ˆìš© ì˜¤ì°¨
```

---

## ğŸ¯ 5. í•µì‹¬ ì§„ë‹¨ ì‹œìŠ¤í…œ (1ìˆœìœ„)

### ğŸ§ª 5.1 1ë¬¸ì œ 30ì„ íƒì§€ í˜ì‹ ì  ì§„ë‹¨
```http
GET /diagnosis/multi-choice/sample
```

**ì§„ë‹¨ ë¬¸ì œ ìƒì„± ê³¼ì •:**
```python
class MultiChoiceDiagnosticEngine:
    def generate_diagnostic_test(self):
        # 1. ê¸°ë³¸ ë¬¸ì œ ì„ íƒ
        base_question = "ì»´í“¨í„° ìŠ¤í ë§ì´ ë¬´ì—‡ì¸ê°€ìš”?"
        correct_answer = "computer"
        
        # 2. ìœ ì‚¬ ì„ íƒì§€ ìƒì„± (AI ê¸°ë°˜)
        similar_choices = self.generate_similar_choices(correct_answer, count=29)
        
        # 3. ì„ íƒì§€ ë°°ì¹˜ (ì •ë‹µ ìœ„ì¹˜ ëœë¤)
        all_choices = [correct_answer] + similar_choices
        random.shuffle(all_choices)
        correct_index = all_choices.index(correct_answer)
        
        # 4. ì¸ì§€ ëŠ¥ë ¥ ì¸¡ì • ì§€í‘œ ì„¤ì •
        cognitive_metrics = [
            "pattern_recognition",    # íŒ¨í„´ ì¸ì‹
            "logical_reasoning",      # ë…¼ë¦¬ì  ì¶”ë¡ 
            "decision_making",        # ì˜ì‚¬ê²°ì •
            "attention_focus",        # ì£¼ì˜ ì§‘ì¤‘
            "time_management",        # ì‹œê°„ ê´€ë¦¬
            "strategic_thinking"      # ì „ëµì  ì‚¬ê³ 
        ]
        
        return MultiChoiceTest(
            question=base_question,
            choices=all_choices,
            correct_index=correct_index,
            cognitive_metrics=cognitive_metrics,
            session_id=self.create_session()
        )
```

### ğŸ“Š 5.2 ì¸ì§€ ëŠ¥ë ¥ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜
```python
def analyze_cognitive_abilities(response: MultiChoiceResponse):
    analysis = {}
    
    # 1. íŒ¨í„´ ì¸ì‹ ëŠ¥ë ¥
    eliminated_pattern = analyze_elimination_pattern(response.eliminated_choices)
    analysis['pattern_recognition'] = calculate_pattern_score(eliminated_pattern)
    
    # 2. ì „ëµì  ì‚¬ê³ 
    strategy_type = identify_strategy_type(response.choice_timeline)
    analysis['strategic_thinking'] = rate_strategy_effectiveness(strategy_type)
    
    # 3. ì‹œê°„ ê´€ë¦¬
    time_distribution = analyze_time_distribution(response.choice_timeline)
    analysis['time_management'] = evaluate_time_efficiency(time_distribution)
    
    # 4. ì˜ì‚¬ê²°ì • í’ˆì§ˆ
    decision_confidence = response.confidence_level
    decision_accuracy = response.selected_choice_index == correct_index
    analysis['decision_making'] = combine_confidence_accuracy(
        decision_confidence, decision_accuracy
    )
    
    # 5. ì£¼ì˜ ì§‘ì¤‘ë ¥
    focus_score = calculate_focus_score(
        response.time_spent_seconds,
        len(response.eliminated_choices),
        response.choice_timeline
    )
    analysis['attention_focus'] = focus_score
    
    return analysis
```

---

## ğŸ”„ 6. ì‹œìŠ¤í…œ í†µí•© ë° ë°ì´í„° í”Œë¡œìš°

### ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì—°ê´€ê´€ê³„
```sql
-- í•µì‹¬ í…Œì´ë¸” ê´€ê³„
Users (1) â†â†’ (N) DiagnosisResults
Users (1) â†â†’ (N) UserHistories  
Users (1) â†â†’ (N) ClassEnrollments
Classes (1) â†â†’ (N) Assignments
DiagnosisResults (1) â†â†’ (N) MultiChoiceTestSessions
```

### ğŸ”„ API ê°„ ë°ì´í„° íë¦„
```mermaid
graph TD
    A[ë¡œê·¸ì¸] â†’ B[JWT í† í°]
    B â†’ C[ëŒ€ì‹œë³´ë“œ API]
    C â†’ D[ì§„ë‹¨ API í˜¸ì¶œ]
    D â†’ E[AI ë¶„ì„ ìš”ì²­]
    E â†’ F[ê²°ê³¼ ì €ì¥]
    F â†’ G[ì¶”ì²œ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸]
    G â†’ H[ëŒ€ì‹œë³´ë“œ ê°±ì‹ ]
```

### ğŸš€ ì„±ëŠ¥ ìµœì í™” ì „ëµ

#### 1. ìºì‹± ì‹œìŠ¤í…œ
```python
# Redis ìºì‹± ì˜ˆì‹œ
@lru_cache(maxsize=1000)
async def get_user_dashboard(user_id: int):
    cache_key = f"dashboard:{user_id}"
    cached_data = await redis.get(cache_key)
    
    if cached_data:
        return json.loads(cached_data)
    
    # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ
    dashboard_data = await fetch_dashboard_data(user_id)
    
    # 5ë¶„ê°„ ìºì‹œ
    await redis.setex(cache_key, 300, json.dumps(dashboard_data))
    return dashboard_data
```

#### 2. ë¹„ë™ê¸° ì²˜ë¦¬
```python
async def process_diagnosis_result(result_data):
    # ë™ì‹œ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ
    tasks = [
        save_diagnosis_result(result_data),
        update_user_statistics(result_data.user_id),
        trigger_ai_analysis(result_data),
        send_notification(result_data.user_id)
    ]
    
    await asyncio.gather(*tasks)
```

---

## ğŸ¨ í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ ìƒì„¸ ê°€ì´ë“œ

### ğŸ“± React ìƒíƒœ ê´€ë¦¬ ì „ëµ
```javascript
// Context API í™œìš©í•œ ì „ì—­ ìƒíƒœ ê´€ë¦¬
const AppContext = createContext();

const AppProvider = ({ children }) => {
  const [user, setUser] = useState(null);
  const [dashboard, setDashboard] = useState(null);
  const [aiInsights, setAiInsights] = useState(null);

  // API í˜¸ì¶œ í†µí•© í•¨ìˆ˜
  const apiCall = useCallback(async (endpoint, options = {}) => {
    const token = localStorage.getItem('token');
    const response = await fetch(`http://localhost:8000/api${endpoint}`, {
      headers: {
        'Authorization': `Bearer ${token}`,
        'Content-Type': 'application/json',
        ...options.headers
      },
      ...options
    });

    if (!response.ok) {
      throw new Error(`API í˜¸ì¶œ ì‹¤íŒ¨: ${response.status}`);
    }

    return response.json();
  }, []);

  return (
    <AppContext.Provider value={{ 
      user, setUser, 
      dashboard, setDashboard,
      aiInsights, setAiInsights,
      apiCall 
    }}>
      {children}
    </AppContext.Provider>
  );
};
```

### ğŸ¯ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ
```javascript
// WebSocket ì—°ê²° (í–¥í›„ í™•ì¥)
const useRealTimeUpdates = (userId) => {
  useEffect(() => {
    const eventSource = new EventSource(
      `http://localhost:8000/api/stream/updates/${userId}`
    );

    eventSource.onmessage = (event) => {
      const update = JSON.parse(event.data);
      
      switch (update.type) {
        case 'dashboard_update':
          setDashboard(prev => ({ ...prev, ...update.data }));
          break;
        case 'new_recommendation':
          showNotification('ìƒˆë¡œìš´ í•™ìŠµ ì¶”ì²œì´ ìˆìŠµë‹ˆë‹¤!');
          break;
        case 'ai_analysis_complete':
          setAiInsights(update.data);
          break;
      }
    };

    return () => eventSource.close();
  }, [userId]);
};
```

### ğŸ“Š ì°¨íŠ¸ ì»´í¬ë„ŒíŠ¸ ì˜ˆì‹œ
```javascript
// í•™ìŠµ ì§„ë„ ì°¨íŠ¸ ì»´í¬ë„ŒíŠ¸
const ProgressChart = ({ data }) => {
  const chartConfig = {
    type: 'line',
    data: {
      labels: data.map(d => d.date),
      datasets: [{
        label: 'í•™ìŠµ ìˆ˜ì¤€',
        data: data.map(d => d.level),
        borderColor: '#3B82F6',
        backgroundColor: 'rgba(59, 130, 246, 0.1)',
        tension: 0.4
      }]
    },
    options: {
      responsive: true,
      plugins: {
        legend: { position: 'top' },
        title: { 
          display: true, 
          text: '30ì¼ê°„ í•™ìŠµ ì§„ë„ ë³€í™”' 
        }
      },
      scales: {
        y: {
          beginAtZero: true,
          max: 1,
          ticks: {
            callback: (value) => `${(value * 100).toFixed(0)}%`
          }
        }
      }
    }
  };

  return <Line data={chartConfig.data} options={chartConfig.options} />;
};
```

---

## âš¡ ê°œë°œ í™˜ê²½ ì„¤ì •

### ğŸ› ï¸ ë°±ì—”ë“œ ì‹¤í–‰ í™˜ê²½
```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export DATABASE_URL="postgresql://user:password@localhost/campuson"
export OPENAI_API_KEY="your-openai-api-key"
export JWT_SECRET_KEY="your-secret-key"

# ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
alembic upgrade head

# ì„œë²„ ì‹¤í–‰
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…
```python
# ë¡œê¹… ì„¤ì •
import logging
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

# êµ¬ì¡°í™”ëœ ë¡œê¹…
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('campuson.log'),
        logging.StreamHandler()
    ]
)

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    
    logger.info(f"Path: {request.url.path} | Duration: {process_time:.3f}s | Status: {response.status_code}")
    return response
```

---

## ğŸ‰ êµ¬í˜„ ì™„ë£Œ í˜„í™© ë° í™•ì¥ ê³„íš

### âœ… ì™„ë£Œëœ ì‹œìŠ¤í…œ
- **ì¸ì¦ ì‹œìŠ¤í…œ**: JWT ê¸°ë°˜ ë³´ì•ˆ ì¸ì¦
- **ì§„ë‹¨ ì‹œìŠ¤í…œ**: 1ë¬¸ì œ 30ì„ íƒì§€ í˜ì‹ ì  ì§„ë‹¨
- **AI ë¶„ì„**: OpenAI ê¸°ë°˜ í•™ìŠµ íŒ¨í„´ ë¶„ì„
- **ëŒ€ì‹œë³´ë“œ**: í•™ìƒ/êµìˆ˜ ë§ì¶¤í˜• ëŒ€ì‹œë³´ë“œ
- **ë³´ì•ˆ**: ë‹¤ì¸µ ë³´ì•ˆ ë° 2FA ì‹œìŠ¤í…œ
- **API**: ì´ 40+ ì—”ë“œí¬ì¸íŠ¸ ì™„ì„±

### ğŸš€ í–¥í›„ í™•ì¥ ê¸°ëŠ¥
1. **ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ** (WebSocket)
2. **ëª¨ë°”ì¼ ì•± API** í™•ì¥
3. **ë¹…ë°ì´í„° ë¶„ì„** (Apache Kafka)
4. **ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤** ì•„í‚¤í…ì²˜ ì „í™˜
5. **ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸** ìì²´ êµ¬ì¶•

### ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ
- **ì‘ë‹µ ì‹œê°„**: í‰ê·  200ms ì´í•˜
- **ë™ì‹œ ì‚¬ìš©ì**: 1000ëª… ì§€ì›
- **AI ë¶„ì„**: 5ì´ˆ ì´ë‚´ ì™„ë£Œ
- **ë°ì´í„°ë² ì´ìŠ¤**: 99.9% ê°€ìš©ì„±

---

## ğŸ“ ê°œë°œ ì§€ì›

### ğŸ› ë””ë²„ê¹… ê°€ì´ë“œ
```bash
# ë¡œê·¸ í™•ì¸
tail -f campuson.log

# ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸
python -c "from app.database import engine; print(engine.execute('SELECT 1').scalar())"

# API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
curl -X GET "http://localhost:8000/api/dashboard/overview" \
  -H "Authorization: Bearer YOUR_TOKEN"
```

### ğŸ“š ì¶”ê°€ ë¬¸ì„œ
- **API ë¬¸ì„œ**: `http://localhost:8000/docs`
- **ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ**: `database_schema.md`
- **ë°°í¬ ê°€ì´ë“œ**: `deployment_guide.md`

---

**ğŸ¯ ì´ì œ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!** 
ëª¨ë“  ë°±ì—”ë“œ ì¸í”„ë¼ê°€ ì™„ì„±ë˜ì—ˆìœ¼ë©°, 40+ API ì—”ë“œí¬ì¸íŠ¸ê°€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤. 